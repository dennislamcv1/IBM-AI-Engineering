{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## get the data\n",
    "#!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x18f7331a408>,\n",
       " <keras.layers.core.Dense at 0x18f7c497388>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x18f5d0b2f48>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x18f5cea2fc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5cea20c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5cecbb48>,\n",
       " <keras.layers.core.Activation at 0x18f5cecba48>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x18f5d114f08>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x18f5d78ef08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5d836488>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5d836c08>,\n",
       " <keras.layers.core.Activation at 0x18f5d83f888>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5d84b708>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5d8db948>,\n",
       " <keras.layers.core.Activation at 0x18f5d8db9c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5d94c588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5d9e1f08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5d9e1888>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5da4bfc8>,\n",
       " <keras.layers.merge.Add at 0x18f5db61e88>,\n",
       " <keras.layers.core.Activation at 0x18f5db5ae48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5dbbe188>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5dc5dd88>,\n",
       " <keras.layers.core.Activation at 0x18f5dc659c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5dc6cf88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5dcffe08>,\n",
       " <keras.layers.core.Activation at 0x18f5dd797c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5dd35d08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5dd6dfc8>,\n",
       " <keras.layers.merge.Add at 0x18f5e093a88>,\n",
       " <keras.layers.core.Activation at 0x18f5e08c748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5e0f0088>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5e194a48>,\n",
       " <keras.layers.core.Activation at 0x18f5e194388>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5e1a5a88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5e22cec8>,\n",
       " <keras.layers.core.Activation at 0x18f5e29dd08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5e2a3448>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5e29dec8>,\n",
       " <keras.layers.merge.Add at 0x18f5e3aac88>,\n",
       " <keras.layers.core.Activation at 0x18f5e3b00c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5e3fa508>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5f483fc8>,\n",
       " <keras.layers.core.Activation at 0x18f5f483e88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5f48aec8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5f547c88>,\n",
       " <keras.layers.core.Activation at 0x18f5f591dc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5f598588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5faa9ec8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5faa9e08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5fb15308>,\n",
       " <keras.layers.merge.Add at 0x18f5fbbf088>,\n",
       " <keras.layers.core.Activation at 0x18f5fbbacc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5fc1c588>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5fcc3808>,\n",
       " <keras.layers.core.Activation at 0x18f5fcc3c88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5fcd5ac8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5fcc37c8>,\n",
       " <keras.layers.core.Activation at 0x18f5fdd8d48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5fdd1508>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5fe8e708>,\n",
       " <keras.layers.merge.Add at 0x18f5fed9c48>,\n",
       " <keras.layers.core.Activation at 0x18f5fedf8c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5ff28448>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f5ffe2b08>,\n",
       " <keras.layers.core.Activation at 0x18f5ffe2dc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f5ffe8c48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f60083cc8>,\n",
       " <keras.layers.core.Activation at 0x18f60083d48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f600f7c88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f60189ec8>,\n",
       " <keras.layers.merge.Add at 0x18f601f6f88>,\n",
       " <keras.layers.core.Activation at 0x18f601fe208>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f60264288>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f603094c8>,\n",
       " <keras.layers.core.Activation at 0x18f60309c48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f60316548>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f603acdc8>,\n",
       " <keras.layers.core.Activation at 0x18f603ac6c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f60418e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f60cc49c8>,\n",
       " <keras.layers.merge.Add at 0x18f60cc4a48>,\n",
       " <keras.layers.core.Activation at 0x18f60d3ffc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f60d7c848>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f60d2eec8>,\n",
       " <keras.layers.core.Activation at 0x18f60e3e788>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f60e45bc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f60ed5c08>,\n",
       " <keras.layers.core.Activation at 0x18f60f54648>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f60f4c088>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6206b588>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f62019188>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f620b9d08>,\n",
       " <keras.layers.merge.Add at 0x18f6216ec08>,\n",
       " <keras.layers.core.Activation at 0x18f62175588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f621c2188>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f62275d48>,\n",
       " <keras.layers.core.Activation at 0x18f62275ec8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f62286588>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f62385a08>,\n",
       " <keras.layers.core.Activation at 0x18f62385e48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6238b308>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f62421cc8>,\n",
       " <keras.layers.merge.Add at 0x18f62421d48>,\n",
       " <keras.layers.core.Activation at 0x18f6249d348>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f624dbac8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6248cec8>,\n",
       " <keras.layers.core.Activation at 0x18f6259b788>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f625a2c08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f62634c48>,\n",
       " <keras.layers.core.Activation at 0x18f626b20c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f626ab048>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6274ae08>,\n",
       " <keras.layers.merge.Add at 0x18f6274a708>,\n",
       " <keras.layers.core.Activation at 0x18f627b83c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f62805208>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f628bbdc8>,\n",
       " <keras.layers.core.Activation at 0x18f628bbf08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f628ca908>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f62963a08>,\n",
       " <keras.layers.core.Activation at 0x18f62963a88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f629d14c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f64b81c08>,\n",
       " <keras.layers.merge.Add at 0x18f64c01648>,\n",
       " <keras.layers.core.Activation at 0x18f64bf9708>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f64c5e0c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f64d03208>,\n",
       " <keras.layers.core.Activation at 0x18f64d03e08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f64d15b48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f64dc5e48>,\n",
       " <keras.layers.core.Activation at 0x18f64e09f48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f64e10248>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f64e10b48>,\n",
       " <keras.layers.merge.Add at 0x18f64f1ad08>,\n",
       " <keras.layers.core.Activation at 0x18f64f20988>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f64f66708>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f65020b88>,\n",
       " <keras.layers.core.Activation at 0x18f6502fe08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f650285c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f650c4d08>,\n",
       " <keras.layers.core.Activation at 0x18f6513f708>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f65137908>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6512ee88>,\n",
       " <keras.layers.merge.Add at 0x18f65244048>,\n",
       " <keras.layers.core.Activation at 0x18f6523c0c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6523cd08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f65347fc8>,\n",
       " <keras.layers.core.Activation at 0x18f65347d08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f65356c48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f653ed708>,\n",
       " <keras.layers.core.Activation at 0x18f653ed808>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6545e388>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6a6e2d48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6a6e2cc8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6a74cec8>,\n",
       " <keras.layers.merge.Add at 0x18f6a865d88>,\n",
       " <keras.layers.core.Activation at 0x18f6a85cf48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6a8c2148>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6a95ff48>,\n",
       " <keras.layers.core.Activation at 0x18f6a95fe88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6a966ac8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6a95fec8>,\n",
       " <keras.layers.core.Activation at 0x18f6aa7f748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6aa76188>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6aa6fcc8>,\n",
       " <keras.layers.merge.Add at 0x18f6ab13f48>,\n",
       " <keras.layers.core.Activation at 0x18f6ab84d48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6abd3088>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6ac86d08>,\n",
       " <keras.layers.core.Activation at 0x18f6ac86fc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6ac95c88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f6ad2c748>,\n",
       " <keras.layers.core.Activation at 0x18f6ad2c848>,\n",
       " <keras.layers.convolutional.Conv2D at 0x18f6ad9bf08>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x18f7324fd08>,\n",
       " <keras.layers.merge.Add at 0x18f732cd708>,\n",
       " <keras.layers.core.Activation at 0x18f732c5cc8>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x18f6ab7d308>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)/60  #Added due to long training times\n",
    "steps_per_epoch_validation = len(validation_generator)/20 #Added due to long training times\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 726s 73s/step - loss: 0.3162 - accuracy: 0.8800 - val_loss: 0.3251 - val_accuracy: 0.9190\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
